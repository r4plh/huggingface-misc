{"repo_name": ["kmike/scikit-learn", "mne-tools/mne-tools.github.io", "bijanfallah/OI_CCLM", "hsu/chrono", "lancezlin/ml_template_py", "wavelets/zipline", "ChanChiChoi/scikit-learn", "rcolasanti/CompaniesHouseScraper", "mclaughlin6464/pasta"], "path": ["sklearn/utils/__init__.py", "0.20/_downloads/76822bb92a8465181ec2a7ee96ca8cf4/plot_decoding_csp_timefreq.py", "src/RMSE_MAPS_INGO.py", "src/demos/trackVehicle/validationPlots_test_M113.py", "lib/python2.7/site-packages/sklearn/metrics/tests/test_score_objects.py", "zipline/examples/dual_ema_talib.py", "examples/model_selection/plot_roc.py", "DVLACompanyNmeMatchCoHoAPIFindMissing.py", "pasta/ising.py"], "copies": ["3", "1", "1", "5", "15", "2", "146", "1", "1"], "size": ["10094", "6457", "2007", "4229", "17443", "3230", "3697", "5174", "5474"], "content": ["\"\"\"\nThe :mod:`sklearn.utils` module includes various utilites.\n\"\"\"\n\nfrom collections import Sequence\n\nimport numpy as np\nfrom scipy.sparse import issparse\nimport warnings\n\nfrom .murmurhash import murmurhash3_32\nfrom .validation import (as_float_array, check_arrays, safe_asarray,\n                         assert_all_finite, array2d, atleast2d_or_csc,\n                         atleast2d_or_csr, warn_if_not_float,\n                         check_random_state)\nfrom .class_weight import compute_class_weight\n\n__all__ = [\"murmurhash3_32\", \"as_float_array\", \"check_arrays\", \"safe_asarray\",\n           \"assert_all_finite\", \"array2d\", \"atleast2d_or_csc\",\n           \"atleast2d_or_csr\", \"warn_if_not_float\", \"check_random_state\",\n           \"compute_class_weight\"]\n\n# Make sure that DeprecationWarning get printed\nwarnings.simplefilter(\"always\", DeprecationWarning)\n\n\nclass deprecated(object):\n    \"\"\"Decorator to mark a function or class as deprecated.\n\n    Issue a warning when the function is called/the class is instantiated and\n    adds a warning to the docstring.\n\n    The optional extra argument will be appended to the deprecation message\n    and the docstring. Note: to use this with the default value for extra, put\n    in an empty of parentheses:\n\n    >>> from sklearn.utils import deprecated\n    >>> deprecated() # doctest: +ELLIPSIS\n    <sklearn.utils.deprecated object at ...>\n\n    >>> @deprecated()\n    ... def some_function(): pass\n    \"\"\"\n\n    # Adapted from http://wiki.python.org/moin/PythonDecoratorLibrary,\n    # but with many changes.\n\n    def __init__(self, extra=''):\n        \"\"\"\n        Parameters\n        ----------\n        extra: string\n          to be added to the deprecation messages\n\n        \"\"\"\n        self.extra = extra\n\n    def __call__(self, obj):\n        if isinstance(obj, type):\n            return self._decorate_class(obj)\n        else:\n            return self._decorate_fun(obj)\n\n    def _decorate_class(self, cls):\n        msg = \"Class %s is deprecated\" % cls.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        # FIXME: we should probably reset __new__ for full generality\n        init = cls.__init__\n\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=DeprecationWarning)\n            return init(*args, **kwargs)\n        cls.__init__ = wrapped\n\n        wrapped.__name__ = '__init__'\n        wrapped.__doc__ = self._update_doc(init.__doc__)\n        wrapped.deprecated_original = init\n\n        return cls\n\n    def _decorate_fun(self, fun):\n        \"\"\"Decorate function fun\"\"\"\n\n        msg = \"Function %s is deprecated\" % fun.__name__\n        if self.extra:\n            msg += \"; %s\" % self.extra\n\n        def wrapped(*args, **kwargs):\n            warnings.warn(msg, category=DeprecationWarning)\n            return fun(*args, **kwargs)\n\n        wrapped.__name__ = fun.__name__\n        wrapped.__dict__ = fun.__dict__\n        wrapped.__doc__ = self._update_doc(fun.__doc__)\n\n        return wrapped\n\n    def _update_doc(self, olddoc):\n        newdoc = \"DEPRECATED\"\n        if self.extra:\n            newdoc = \"%s: %s\" % (newdoc, self.extra)\n        if olddoc:\n            newdoc = \"%s\\n\\n%s\" % (newdoc, olddoc)\n        return newdoc\n\n\ndef safe_mask(X, mask):\n    \"\"\"Return a mask which is safe to use on X.\n\n    Parameters\n    ----------\n    X : {array-like, sparse matrix}\n        Data on which to apply mask.\n\n    mask: array\n        Mask to be used on X.\n\n    Returns\n    -------\n        mask\n    \"\"\"\n    mask = np.asanyarray(mask)\n    if np.issubdtype(mask.dtype, np.int):\n        return mask\n\n    if hasattr(X, \"toarray\"):\n        ind = np.arange(mask.shape[0])\n        mask = ind[mask]\n    return mask\n\n\ndef resample(*arrays, **options):\n    \"\"\"Resample arrays or sparse matrices in a consistent way\n\n    The default strategy implements one step of the bootstrapping\n    procedure.\n\n    Parameters\n    ----------\n    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\n\n    replace : boolean, True by default\n        Implements resampling with replacement. If False, this will implement\n        (sliced) random permutations.\n\n    n_samples : int, None by default\n        Number of samples to generate. If left to None this is\n        automatically set to the first dimension of the arrays.\n\n    random_state : int or RandomState instance\n        Control the shuffling for reproducible behavior.\n\n    Returns\n    -------\n    Sequence of resampled views of the collections. The original arrays are\n    not impacted.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import resample\n      >>> X, X_sparse, y = resample(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[ 1.,  0.],\n             [ 2.,  1.],\n             [ 1.,  0.]])\n\n      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n      <3x2 sparse matrix of type '<... 'numpy.float64'>'\n          with 4 stored elements in Compressed Sparse Row format>\n\n      >>> X_sparse.toarray()\n      array([[ 1.,  0.],\n             [ 2.,  1.],\n             [ 1.,  0.]])\n\n      >>> y\n      array([0, 1, 0])\n\n      >>> resample(y, n_samples=2, random_state=0)\n      array([0, 1])\n\n\n    See also\n    --------\n    :class:`sklearn.cross_validation.Bootstrap`\n    :func:`sklearn.utils.shuffle`\n    \"\"\"\n    random_state = check_random_state(options.pop('random_state', None))\n    replace = options.pop('replace', True)\n    max_n_samples = options.pop('n_samples', None)\n    if options:\n        raise ValueError(\"Unexpected kw arguments: %r\" % options.keys())\n\n    if len(arrays) == 0:\n        return None\n\n    first = arrays[0]\n    n_samples = first.shape[0] if hasattr(first, 'shape') else len(first)\n\n    if max_n_samples is None:\n        max_n_samples = n_samples\n\n    if max_n_samples > n_samples:\n        raise ValueError(\"Cannot sample %d out of arrays with dim %d\" % (\n            max_n_samples, n_samples))\n\n    arrays = check_arrays(*arrays, sparse_format='csr')\n\n    if replace:\n        indices = random_state.randint(0, n_samples, size=(max_n_samples,))\n    else:\n        indices = np.arange(n_samples)\n        random_state.shuffle(indices)\n        indices = indices[:max_n_samples]\n\n    resampled_arrays = []\n\n    for array in arrays:\n        array = array[indices]\n        resampled_arrays.append(array)\n\n    if len(resampled_arrays) == 1:\n        # syntactic sugar for the unit argument case\n        return resampled_arrays[0]\n    else:\n        return resampled_arrays\n\n\ndef shuffle(*arrays, **options):\n    \"\"\"Shuffle arrays or sparse matrices in a consistent way\n\n    This is a convenience alias to ``resample(*arrays, replace=False)`` to do\n    random permutations of the collections.\n\n    Parameters\n    ----------\n    `*arrays` : sequence of arrays or scipy.sparse matrices with same shape[0]\n\n    random_state : int or RandomState instance\n        Control the shuffling for reproducible behavior.\n\n    n_samples : int, None by default\n        Number of samples to generate. If left to None this is\n        automatically set to the first dimension of the arrays.\n\n    Returns\n    -------\n    Sequence of shuffled views of the collections. The original arrays are\n    not impacted.\n\n    Examples\n    --------\n    It is possible to mix sparse and dense arrays in the same run::\n\n      >>> X = [[1., 0.], [2., 1.], [0., 0.]]\n      >>> y = np.array([0, 1, 2])\n\n      >>> from scipy.sparse import coo_matrix\n      >>> X_sparse = coo_matrix(X)\n\n      >>> from sklearn.utils import shuffle\n      >>> X, X_sparse, y = shuffle(X, X_sparse, y, random_state=0)\n      >>> X\n      array([[ 0.,  0.],\n             [ 2.,  1.],\n             [ 1.,  0.]])\n\n      >>> X_sparse                   # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE\n      <3x2 sparse matrix of type '<... 'numpy.float64'>'\n          with 3 stored elements in Compressed Sparse Row format>\n\n      >>> X_sparse.toarray()\n      array([[ 0.,  0.],\n             [ 2.,  1.],\n             [ 1.,  0.]])\n\n      >>> y\n      array([2, 1, 0])\n\n      >>> shuffle(y, n_samples=2, random_state=0)\n      array([0, 1])\n\n    See also\n    --------\n    :func:`sklearn.utils.resample`\n    \"\"\"\n    options['replace'] = False\n    return resample(*arrays, **options)\n\n\ndef safe_sqr(X, copy=True):\n    \"\"\"Element wise squaring of array-likes and sparse matrices.\n\n    Parameters\n    ----------\n    X : array like, matrix, sparse matrix\n\n    Returns\n    -------\n    X ** 2 : element wise square\n    \"\"\"\n    X = safe_asarray(X)\n    if issparse(X):\n        if copy:\n            X = X.copy()\n        X.data **= 2\n    else:\n        if copy:\n            X = X ** 2\n        else:\n            X **= 2\n    return X\n\n\ndef gen_even_slices(n, n_packs):\n    \"\"\"Generator to create n_packs slices going up to n.\n\n    Examples\n    --------\n    >>> from sklearn.utils import gen_even_slices\n    >>> list(gen_even_slices(10, 1))\n    [slice(0, 10, None)]\n    >>> list(gen_even_slices(10, 10))                     #doctest: +ELLIPSIS\n    [slice(0, 1, None), slice(1, 2, None), ..., slice(9, 10, None)]\n    >>> list(gen_even_slices(10, 5))                      #doctest: +ELLIPSIS\n    [slice(0, 2, None), slice(2, 4, None), ..., slice(8, 10, None)]\n    >>> list(gen_even_slices(10, 3))\n    [slice(0, 4, None), slice(4, 7, None), slice(7, 10, None)]\n    \"\"\"\n    start = 0\n    for pack_num in range(n_packs):\n        this_n = n // n_packs\n        if pack_num < n % n_packs:\n            this_n += 1\n        if this_n > 0:\n            end = start + this_n\n            yield slice(start, end, None)\n            start = end\n\n\ndef tosequence(x):\n    \"\"\"Cast iterable x to a Sequence, avoiding a copy if possible.\"\"\"\n    if isinstance(x, np.ndarray):\n        return np.asarray(x)\n    elif isinstance(x, Sequence):\n        return x\n    else:\n        return list(x)\n\n\nclass ConvergenceWarning(Warning):\n    \"Custom warning to capture convergence problems\"\n", "\"\"\"\n============================================================================\nDecoding in time-frequency space data using the Common Spatial Pattern (CSP)\n============================================================================\n\nThe time-frequency decomposition is estimated by iterating over raw data that\nhas been band-passed at different frequencies. This is used to compute a\ncovariance matrix over each epoch or a rolling time-window and extract the CSP\nfiltered signals. A linear discriminant classifier is then applied to these\nsignals.\n\"\"\"\n# Authors: Laura Gwilliams <laura.gwilliams@nyu.edu>\n#          Jean-Remi King <jeanremi.king@gmail.com>\n#          Alex Barachant <alexandre.barachant@gmail.com>\n#          Alexandre Gramfort <alexandre.gramfort@inria.fr>\n#\n# License: BSD (3-clause)\n\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom mne import Epochs, create_info, events_from_annotations\nfrom mne.io import concatenate_raws, read_raw_edf\nfrom mne.datasets import eegbci\nfrom mne.decoding import CSP\nfrom mne.time_frequency import AverageTFR\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import LabelEncoder\n\n###############################################################################\n# Set parameters and read data\nevent_id = dict(hands=2, feet=3)  # motor imagery: hands vs feet\nsubject = 1\nruns = [6, 10, 14]\nraw_fnames = eegbci.load_data(subject, runs)\nraw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n\n# Extract information from the raw file\nsfreq = raw.info['sfreq']\nevents, _ = events_from_annotations(raw, event_id=dict(T1=2, T2=3))\nraw.pick_types(meg=False, eeg=True, stim=False, eog=False, exclude='bads')\n\n# Assemble the classifier using scikit-learn pipeline\nclf = make_pipeline(CSP(n_components=4, reg=None, log=True, norm_trace=False),\n                    LinearDiscriminantAnalysis())\nn_splits = 5  # how many folds to use for cross-validation\ncv = StratifiedKFold(n_splits=n_splits, shuffle=True)\n\n# Classification & Time-frequency parameters\ntmin, tmax = -.200, 2.000\nn_cycles = 10.  # how many complete cycles: used to define window size\nmin_freq = 5.\nmax_freq = 25.\nn_freqs = 8  # how many frequency bins to use\n\n# Assemble list of frequency range tuples\nfreqs = np.linspace(min_freq, max_freq, n_freqs)  # assemble frequencies\nfreq_ranges = list(zip(freqs[:-1], freqs[1:]))  # make freqs list of tuples\n\n# Infer window spacing from the max freq and number of cycles to avoid gaps\nwindow_spacing = (n_cycles / np.max(freqs) / 2.)\ncentered_w_times = np.arange(tmin, tmax, window_spacing)[1:]\nn_windows = len(centered_w_times)\n\n# Instantiate label encoder\nle = LabelEncoder()\n\n###############################################################################\n# Loop through frequencies, apply classifier and save scores\n\n# init scores\nfreq_scores = np.zeros((n_freqs - 1,))\n\n# Loop through each frequency range of interest\nfor freq, (fmin, fmax) in enumerate(freq_ranges):\n\n    # Infer window size based on the frequency being used\n    w_size = n_cycles / ((fmax + fmin) / 2.)  # in seconds\n\n    # Apply band-pass filter to isolate the specified frequencies\n    raw_filter = raw.copy().filter(fmin, fmax, n_jobs=1, fir_design='firwin',\n                                   skip_by_annotation='edge')\n\n    # Extract epochs from filtered data, padded by window size\n    epochs = Epochs(raw_filter, events, event_id, tmin - w_size, tmax + w_size,\n                    proj=False, baseline=None, preload=True)\n    epochs.drop_bad()\n    y = le.fit_transform(epochs.events[:, 2])\n\n    X = epochs.get_data()\n\n    # Save mean scores over folds for each frequency and time window\n    freq_scores[freq] = np.mean(cross_val_score(estimator=clf, X=X, y=y,\n                                                scoring='roc_auc', cv=cv,\n                                                n_jobs=1), axis=0)\n\n###############################################################################\n# Plot frequency results\n\nplt.bar(freqs[:-1], freq_scores, width=np.diff(freqs)[0],\n        align='edge', edgecolor='black')\nplt.xticks(freqs)\nplt.ylim([0, 1])\nplt.axhline(len(epochs['feet']) / len(epochs), color='k', linestyle='--',\n            label='chance level')\nplt.legend()\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Decoding Scores')\nplt.title('Frequency Decoding Scores')\n\n###############################################################################\n# Loop through frequencies and time, apply classifier and save scores\n\n# init scores\ntf_scores = np.zeros((n_freqs - 1, n_windows))\n\n# Loop through each frequency range of interest\nfor freq, (fmin, fmax) in enumerate(freq_ranges):\n\n    # Infer window size based on the frequency being used\n    w_size = n_cycles / ((fmax + fmin) / 2.)  # in seconds\n\n    # Apply band-pass filter to isolate the specified frequencies\n    raw_filter = raw.copy().filter(fmin, fmax, n_jobs=1, fir_design='firwin',\n                                   skip_by_annotation='edge')\n\n    # Extract epochs from filtered data, padded by window size\n    epochs = Epochs(raw_filter, events, event_id, tmin - w_size, tmax + w_size,\n                    proj=False, baseline=None, preload=True)\n    epochs.drop_bad()\n    y = le.fit_transform(epochs.events[:, 2])\n\n    # Roll covariance, csp and lda over time\n    for t, w_time in enumerate(centered_w_times):\n\n        # Center the min and max of the window\n        w_tmin = w_time - w_size / 2.\n        w_tmax = w_time + w_size / 2.\n\n        # Crop data into time-window of interest\n        X = epochs.copy().crop(w_tmin, w_tmax).get_data()\n\n        # Save mean scores over folds for each frequency and time window\n        tf_scores[freq, t] = np.mean(cross_val_score(estimator=clf, X=X, y=y,\n                                                     scoring='roc_auc', cv=cv,\n                                                     n_jobs=1), axis=0)\n\n###############################################################################\n# Plot time-frequency results\n\n# Set up time frequency object\nav_tfr = AverageTFR(create_info(['freq'], sfreq), tf_scores[np.newaxis, :],\n                    centered_w_times, freqs[1:], 1)\n\nchance = np.mean(y)  # set chance level to white in the plot\nav_tfr.plot([0], vmin=chance, title=\"Time-Frequency Decoding Scores\",\n            cmap=plt.cm.Reds)\n", "# Program to show the maps of RMSE averaged over time\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import mean_squared_error\nimport os\nfrom netCDF4 import Dataset as NetCDFFile\nimport numpy as np\nfrom CCLM_OUTS import Plot_CCLM\n# option == 1 ->  shift 4 with default cclm domain and nboundlines = 3\n# option == 2 ->  shift 4 with smaller cclm domain and nboundlines = 3\n# option == 3 ->  shift 4 with smaller cclm domain and nboundlines = 6\n# option == 4 ->  shift 4 with corrected smaller cclm domain and nboundlines = 3\n# option == 5 ->  shift 4 with corrected smaller cclm domain and nboundlines = 4\n# option == 6 ->  shift 4 with corrected smaller cclm domain and nboundlines = 6\n# option == 7 ->  shift 4 with corrected smaller cclm domain and nboundlines = 9\n# option == 8 ->  shift 4 with corrected bigger cclm domain and nboundlines = 3\nfrom CCLM_OUTS import Plot_CCLM\n#def f(x):\n#   if x==-9999:\n#      return float('NaN')\n#   else:\n#      return x\ndef read_data_from_mistral(dir='/work/bb1029/b324045/work1/work/member/post/',name='member_T_2M_ts_seasmean.nc',var='T_2M'):\n    # type: (object, object, object) -> object\n    #a function to read the data from mistral work\n\n    \"\"\"\n\n    :rtype: object\n    \"\"\"\n    #CMD = 'scp $mistral:' + dir + name + ' ./'\n    CMD = 'wget users.met.fu-berlin.de/~BijanFallah/' + dir + name\n    os.system(CMD)\n    nc = NetCDFFile(name)\n#    for name2, variable in nc.variables.items():\n#        for attrname in variable.ncattrs():\n#                    print(name2, variable, '-----------------',attrname)\n#                    #print(\"{} -- {}\".format(attrname, getattr(variable, attrname)))\n    os.remove(name)\n    lats = nc.variables['lat'][:]\n    lons = nc.variables['lon'][:]\n    t = nc.variables[var][:].squeeze()\n    rlats = nc.variables['rlat'][:]  # extract/copy the data\n    rlons = nc.variables['rlon'][:]\n    #f2 = np.vectorize(f)\n    #t= f2(t)\n    #t=t.data\n    t=t.squeeze()\n    #print()\n    nc.close()\n\n    return(t, lats, lons, rlats, rlons)\n\n", "# -*- coding: utf-8 -*-\n\"\"\"\nCreated on Wed May 06 11:00:53 2015\n\n@author: newJustin\n\"\"\"\n\nimport ChronoTrack_pandas as CT\nimport pylab as py\n      \nif __name__ == '__main__':\n    \n    # logger\n    import logging as lg\n    \n    lg.basicConfig(fileName = 'logFile.log', level=lg.WARN, format='%(message)s')\n    # default font size\n\n    import matplotlib\n    font = {'size' : 14}\n    matplotlib.rc('font', **font)       \n    \n    #  **********************************************************************    \n    #  ===============   USER INPUT   =======================================\n    # data dir, end w/ '/'\n    # data_dir = 'D:/Chrono_github_Build/bin/outdata_M113/'\n    data_dir = 'E:/Chrono_github_Build/bin/outdata_M113/'    \n    \n    '''    \n    # list of data files to plot\n    chassis = 'M113_chassis.csv'\n    gearSubsys = 'M113_Side0_gear.csv'\n    idlerSubsys = 'M113_Side0_idler.csv'\n    # ptrainSubsys = 'test_driveChain_ptrain.csv'\n    shoe0 = 'M113_Side0_shoe0.csv'\n    '''\n    chassis = 'M113_400_200__chassis.csv'\n    gearSubsys = 'M113_400_200__Side0_gear.csv'\n    idlerSubsys = 'M113_400_200__Side0_idler.csv'\n    # ptrainSubsys = 'test_driveChain_ptrain.csv'\n    shoe0 = 'M113_400_200__Side0_shoe0.csv'    \n\n    data_files = [data_dir + chassis, data_dir + gearSubsys, data_dir + idlerSubsys, data_dir + shoe0]\n    handle_list = ['chassis','gear','idler','shoe0']\n    # handle_list = ['Gear','idler','ptrain','shoe0','gearCV','idlerCV','rollerCV','gearContact','shoeGearContact']\n\n    \n    \n    '''\n    gearCV = 'test_driveChain_GearCV.csv'\n    idlerCV = 'test_driveChain_idler0CV.csv'\n    rollerCV = 'test_driveChain_roller0CV.csv'\n    gearContact = 'test_driveChain_gearContact.csv'\n    shoeGearContact = 'test_driveChain_shoe0GearContact.csv'\n    '''\n    \n    # data_files = [data_dir + gearSubsys, data_dir + idlerSubsys, data_dir + ptrainSubsys, data_dir + shoe0, data_dir + gearCV, data_dir + idlerCV, data_dir + rollerCV, data_dir + gearContact, data_dir+shoeGearContact]\n    # handle_list = ['Gear','idler','ptrain','shoe0','gearCV','idlerCV','rollerCV','gearContact','shoeGearContact']\n\n    \n    # list of data files for gear/pin comparison plots    \n    #  Primitive gear geometry\n    '''\n    gear = 'driveChain_P_gear.csv'\n    gearContact = 'driveChain_P_gearContact.csv'\n    shoe = 'driveChain_P_shoe0.csv'\n    shoeContact = 'driveChain_P_shoe0GearContact.csv'\n    ptrain = 'driveChain_P_ptrain.csv'    \n    \n    \n    #  Collision Callback gear geometry     \n    gear = 'driveChain_CC_gear.csv'\n    gearContact = 'driveChain_CC_gearContact.csv'\n    shoe = 'driveChain_CC_shoe0.csv'\n    shoeContact = 'driveChain_CC_shoe0GearContact.csv'\n    ptrain = 'driveChain_CC_ptrain.csv'    \n    \n    \n    data_files = [data_dir+gear, data_dir+gearContact, data_dir+shoe, data_dir+shoeContact, data_dir+ptrain]\n   \n    handle_list = ['Gear','gearContact','shoe0','shoeGearContact','ptrain']\n    '''\n \n \n    # construct the panda class for the DriveChain, file list and list of legend\n    M113_Chain0 = CT.ChronoTrack_pandas(data_files, handle_list)\n    \n    # set the time limits. tmin = -1 will plot the entire time range\n    tmin = 1.0\n    tmax = 8.0\n    \n    \n    #0) plot the chassis\n    M113_Chain0.plot_chassis(tmin, tmax)    \n    \n    # 1) plot the gear body info\n    M113_Chain0.plot_gear(tmin, tmax)\n    \n    \n    # 2) plot idler body info, tensioner force\n    M113_Chain0.plot_idler(tmin,tmax)\n\n    '''\n    # 3) plot powertrain info\n    M113_Chain0.plot_ptrain()    \n    '''\n    \n    # 4) plot shoe 0 body info, and pin 0 force/torque\n    M113_Chain0.plot_shoe(tmin,tmax)\n    \n    '''\n    # 5) plot gear Constraint Violations\n    M113_Chain0.plot_gearCV(tmin,tmax)\n    \n    # 6) plot idler Constraint Violations\n    M113_Chain0.plot_idlerCV(tmin,tmax)\n    \n    # 7) plot roller Constraint Violations\n    M113_Chain0.plot_rollerCV(tmin,tmax)\n    \n    # 8) from the contact report callback function, gear contact info\n    M113_Chain0.plot_gearContactInfo(tmin,tmax)\n\n    # 9)  from shoe-gear report callback function, contact info\n    M113_Chain0.plot_shoeGearContactInfo(tmin,tmax)\n    '''\n    \n    # 10) track shoe trajectory: rel-X vs. rel-Y\n    M113_Chain0.plot_trajectory(tmin,tmax)\n\n    py.show()", "import pickle\nimport tempfile\nimport shutil\nimport os\nimport numbers\n\nimport numpy as np\n\nfrom sklearn.utils.testing import assert_almost_equal\nfrom sklearn.utils.testing import assert_array_equal\nfrom sklearn.utils.testing import assert_raises\nfrom sklearn.utils.testing import assert_raises_regexp\nfrom sklearn.utils.testing import assert_true\nfrom sklearn.utils.testing import ignore_warnings\nfrom sklearn.utils.testing import assert_not_equal\nfrom sklearn.utils.testing import assert_warns_message\n\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import (f1_score, r2_score, roc_auc_score, fbeta_score,\n                             log_loss, precision_score, recall_score)\nfrom sklearn.metrics.cluster import adjusted_rand_score\nfrom sklearn.metrics.scorer import (check_scoring, _PredictScorer,\n                                    _passthrough_scorer)\nfrom sklearn.metrics import make_scorer, get_scorer, SCORERS\nfrom sklearn.svm import LinearSVC\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.cluster import KMeans\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.linear_model import Ridge, LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.datasets import make_blobs\nfrom sklearn.datasets import make_classification\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.externals import joblib\n\n\nREGRESSION_SCORERS = ['r2', 'neg_mean_absolute_error',\n                      'neg_mean_squared_error', 'neg_median_absolute_error',\n                      'mean_absolute_error',\n                      'mean_squared_error', 'median_absolute_error']\n\nCLF_SCORERS = ['accuracy', 'f1', 'f1_weighted', 'f1_macro', 'f1_micro',\n               'roc_auc', 'average_precision', 'precision',\n               'precision_weighted', 'precision_macro', 'precision_micro',\n               'recall', 'recall_weighted', 'recall_macro', 'recall_micro',\n               'neg_log_loss', 'log_loss',\n               'adjusted_rand_score'  # not really, but works\n               ]\n\nMULTILABEL_ONLY_SCORERS = ['precision_samples', 'recall_samples', 'f1_samples']\n\n\ndef _make_estimators(X_train, y_train, y_ml_train):\n    # Make estimators that make sense to test various scoring methods\n    sensible_regr = DummyRegressor(strategy='median')\n    sensible_regr.fit(X_train, y_train)\n    sensible_clf = DecisionTreeClassifier(random_state=0)\n    sensible_clf.fit(X_train, y_train)\n    sensible_ml_clf = DecisionTreeClassifier(random_state=0)\n    sensible_ml_clf.fit(X_train, y_ml_train)\n    return dict(\n        [(name, sensible_regr) for name in REGRESSION_SCORERS] +\n        [(name, sensible_clf) for name in CLF_SCORERS] +\n        [(name, sensible_ml_clf) for name in MULTILABEL_ONLY_SCORERS]\n    )\n\n\nX_mm, y_mm, y_ml_mm = None, None, None\nESTIMATORS = None\nTEMP_FOLDER = None\n\n\ndef setup_module():\n    # Create some memory mapped data\n    global X_mm, y_mm, y_ml_mm, TEMP_FOLDER, ESTIMATORS\n    TEMP_FOLDER = tempfile.mkdtemp(prefix='sklearn_test_score_objects_')\n    X, y = make_classification(n_samples=30, n_features=5, random_state=0)\n    _, y_ml = make_multilabel_classification(n_samples=X.shape[0],\n                                             random_state=0)\n    filename = os.path.join(TEMP_FOLDER, 'test_data.pkl')\n    joblib.dump((X, y, y_ml), filename)\n    X_mm, y_mm, y_ml_mm = joblib.load(filename, mmap_mode='r')\n    ESTIMATORS = _make_estimators(X_mm, y_mm, y_ml_mm)\n\n\ndef teardown_module():\n    global X_mm, y_mm, y_ml_mm, TEMP_FOLDER, ESTIMATORS\n    # GC closes the mmap file descriptors\n    X_mm, y_mm, y_ml_mm, ESTIMATORS = None, None, None, None\n    shutil.rmtree(TEMP_FOLDER)\n\n\nclass EstimatorWithoutFit(object):\n    \"\"\"Dummy estimator to test check_scoring\"\"\"\n    pass\n\n\nclass EstimatorWithFit(BaseEstimator):\n    \"\"\"Dummy estimator to test check_scoring\"\"\"\n    def fit(self, X, y):\n        return self\n\n\nclass EstimatorWithFitAndScore(object):\n    \"\"\"Dummy estimator to test check_scoring\"\"\"\n    def fit(self, X, y):\n        return self\n\n    def score(self, X, y):\n        return 1.0\n\n\nclass EstimatorWithFitAndPredict(object):\n    \"\"\"Dummy estimator to test check_scoring\"\"\"\n    def fit(self, X, y):\n        self.y = y\n        return self\n\n    def predict(self, X):\n        return self.y\n\n\nclass DummyScorer(object):\n    \"\"\"Dummy scorer that always returns 1.\"\"\"\n    def __call__(self, est, X, y):\n        return 1\n\n\ndef test_all_scorers_repr():\n    # Test that all scorers have a working repr\n    for name, scorer in SCORERS.items():\n        repr(scorer)\n\n\ndef test_check_scoring():\n    # Test all branches of check_scoring\n    estimator = EstimatorWithoutFit()\n    pattern = (r\"estimator should be an estimator implementing 'fit' method,\"\n               r\" .* was passed\")\n    assert_raises_regexp(TypeError, pattern, check_scoring, estimator)\n\n    estimator = EstimatorWithFitAndScore()\n    estimator.fit([[1]], [1])\n    scorer = check_scoring(estimator)\n    assert_true(scorer is _passthrough_scorer)\n    assert_almost_equal(scorer(estimator, [[1]], [1]), 1.0)\n\n    estimator = EstimatorWithFitAndPredict()\n    estimator.fit([[1]], [1])\n    pattern = (r\"If no scoring is specified, the estimator passed should have\"\n               r\" a 'score' method\\. The estimator .* does not\\.\")\n    assert_raises_regexp(TypeError, pattern, check_scoring, estimator)\n\n    scorer = check_scoring(estimator, \"accuracy\")\n    assert_almost_equal(scorer(estimator, [[1]], [1]), 1.0)\n\n    estimator = EstimatorWithFit()\n    scorer = check_scoring(estimator, \"accuracy\")\n    assert_true(isinstance(scorer, _PredictScorer))\n\n    estimator = EstimatorWithFit()\n    scorer = check_scoring(estimator, allow_none=True)\n    assert_true(scorer is None)\n\n\ndef test_check_scoring_gridsearchcv():\n    # test that check_scoring works on GridSearchCV and pipeline.\n    # slightly redundant non-regression test.\n\n    grid = GridSearchCV(LinearSVC(), param_grid={'C': [.1, 1]})\n    scorer = check_scoring(grid, \"f1\")\n    assert_true(isinstance(scorer, _PredictScorer))\n\n    pipe = make_pipeline(LinearSVC())\n    scorer = check_scoring(pipe, \"f1\")\n    assert_true(isinstance(scorer, _PredictScorer))\n\n    # check that cross_val_score definitely calls the scorer\n    # and doesn't make any assumptions about the estimator apart from having a\n    # fit.\n    scores = cross_val_score(EstimatorWithFit(), [[1], [2], [3]], [1, 0, 1],\n                             scoring=DummyScorer())\n    assert_array_equal(scores, 1)\n\n\ndef test_make_scorer():\n    # Sanity check on the make_scorer factory function.\n    f = lambda *args: 0\n    assert_raises(ValueError, make_scorer, f, needs_threshold=True,\n                  needs_proba=True)\n\n\ndef test_classification_scores():\n    # Test classification scorers.\n    X, y = make_blobs(random_state=0, centers=2)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = LinearSVC(random_state=0)\n    clf.fit(X_train, y_train)\n\n    for prefix, metric in [('f1', f1_score), ('precision', precision_score),\n                           ('recall', recall_score)]:\n\n        score1 = get_scorer('%s_weighted' % prefix)(clf, X_test, y_test)\n        score2 = metric(y_test, clf.predict(X_test), pos_label=None,\n                        average='weighted')\n        assert_almost_equal(score1, score2)\n\n        score1 = get_scorer('%s_macro' % prefix)(clf, X_test, y_test)\n        score2 = metric(y_test, clf.predict(X_test), pos_label=None,\n                        average='macro')\n        assert_almost_equal(score1, score2)\n\n        score1 = get_scorer('%s_micro' % prefix)(clf, X_test, y_test)\n        score2 = metric(y_test, clf.predict(X_test), pos_label=None,\n                        average='micro')\n        assert_almost_equal(score1, score2)\n\n        score1 = get_scorer('%s' % prefix)(clf, X_test, y_test)\n        score2 = metric(y_test, clf.predict(X_test), pos_label=1)\n        assert_almost_equal(score1, score2)\n\n    # test fbeta score that takes an argument\n    scorer = make_scorer(fbeta_score, beta=2)\n    score1 = scorer(clf, X_test, y_test)\n    score2 = fbeta_score(y_test, clf.predict(X_test), beta=2)\n    assert_almost_equal(score1, score2)\n\n    # test that custom scorer can be pickled\n    unpickled_scorer = pickle.loads(pickle.dumps(scorer))\n    score3 = unpickled_scorer(clf, X_test, y_test)\n    assert_almost_equal(score1, score3)\n\n    # smoke test the repr:\n    repr(fbeta_score)\n\n\ndef test_regression_scorers():\n    # Test regression scorers.\n    diabetes = load_diabetes()\n    X, y = diabetes.data, diabetes.target\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = Ridge()\n    clf.fit(X_train, y_train)\n    score1 = get_scorer('r2')(clf, X_test, y_test)\n    score2 = r2_score(y_test, clf.predict(X_test))\n    assert_almost_equal(score1, score2)\n\n\ndef test_thresholded_scorers():\n    # Test scorers that take thresholds.\n    X, y = make_blobs(random_state=0, centers=2)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X_train, y_train)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, clf.decision_function(X_test))\n    score3 = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n    assert_almost_equal(score1, score2)\n    assert_almost_equal(score1, score3)\n\n    logscore = get_scorer('neg_log_loss')(clf, X_test, y_test)\n    logloss = log_loss(y_test, clf.predict_proba(X_test))\n    assert_almost_equal(-logscore, logloss)\n\n    # same for an estimator without decision_function\n    clf = DecisionTreeClassifier()\n    clf.fit(X_train, y_train)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, clf.predict_proba(X_test)[:, 1])\n    assert_almost_equal(score1, score2)\n\n    # test with a regressor (no decision_function)\n    reg = DecisionTreeRegressor()\n    reg.fit(X_train, y_train)\n    score1 = get_scorer('roc_auc')(reg, X_test, y_test)\n    score2 = roc_auc_score(y_test, reg.predict(X_test))\n    assert_almost_equal(score1, score2)\n\n    # Test that an exception is raised on more than two classes\n    X, y = make_blobs(random_state=0, centers=3)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf.fit(X_train, y_train)\n    assert_raises(ValueError, get_scorer('roc_auc'), clf, X_test, y_test)\n\n\ndef test_thresholded_scorers_multilabel_indicator_data():\n    # Test that the scorer work with multilabel-indicator format\n    # for multilabel and multi-output multi-class classifier\n    X, y = make_multilabel_classification(allow_unlabeled=False,\n                                          random_state=0)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\n    # Multi-output multi-class predict_proba\n    clf = DecisionTreeClassifier()\n    clf.fit(X_train, y_train)\n    y_proba = clf.predict_proba(X_test)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, np.vstack(p[:, -1] for p in y_proba).T)\n    assert_almost_equal(score1, score2)\n\n    # Multi-output multi-class decision_function\n    # TODO Is there any yet?\n    clf = DecisionTreeClassifier()\n    clf.fit(X_train, y_train)\n    clf._predict_proba = clf.predict_proba\n    clf.predict_proba = None\n    clf.decision_function = lambda X: [p[:, 1] for p in clf._predict_proba(X)]\n\n    y_proba = clf.decision_function(X_test)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, np.vstack(p for p in y_proba).T)\n    assert_almost_equal(score1, score2)\n\n    # Multilabel predict_proba\n    clf = OneVsRestClassifier(DecisionTreeClassifier())\n    clf.fit(X_train, y_train)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, clf.predict_proba(X_test))\n    assert_almost_equal(score1, score2)\n\n    # Multilabel decision function\n    clf = OneVsRestClassifier(LinearSVC(random_state=0))\n    clf.fit(X_train, y_train)\n    score1 = get_scorer('roc_auc')(clf, X_test, y_test)\n    score2 = roc_auc_score(y_test, clf.decision_function(X_test))\n    assert_almost_equal(score1, score2)\n\n\ndef test_unsupervised_scorers():\n    # Test clustering scorers against gold standard labeling.\n    # We don't have any real unsupervised Scorers yet.\n    X, y = make_blobs(random_state=0, centers=2)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    km = KMeans(n_clusters=3)\n    km.fit(X_train)\n    score1 = get_scorer('adjusted_rand_score')(km, X_test, y_test)\n    score2 = adjusted_rand_score(y_test, km.predict(X_test))\n    assert_almost_equal(score1, score2)\n\n\n@ignore_warnings\ndef test_raises_on_score_list():\n    # Test that when a list of scores is returned, we raise proper errors.\n    X, y = make_blobs(random_state=0)\n    f1_scorer_no_average = make_scorer(f1_score, average=None)\n    clf = DecisionTreeClassifier()\n    assert_raises(ValueError, cross_val_score, clf, X, y,\n                  scoring=f1_scorer_no_average)\n    grid_search = GridSearchCV(clf, scoring=f1_scorer_no_average,\n                               param_grid={'max_depth': [1, 2]})\n    assert_raises(ValueError, grid_search.fit, X, y)\n\n\n@ignore_warnings\ndef test_scorer_sample_weight():\n    # Test that scorers support sample_weight or raise sensible errors\n\n    # Unlike the metrics invariance test, in the scorer case it's harder\n    # to ensure that, on the classifier output, weighted and unweighted\n    # scores really should be unequal.\n    X, y = make_classification(random_state=0)\n    _, y_ml = make_multilabel_classification(n_samples=X.shape[0],\n                                             random_state=0)\n    split = train_test_split(X, y, y_ml, random_state=0)\n    X_train, X_test, y_train, y_test, y_ml_train, y_ml_test = split\n\n    sample_weight = np.ones_like(y_test)\n    sample_weight[:10] = 0\n\n    # get sensible estimators for each metric\n    estimator = _make_estimators(X_train, y_train, y_ml_train)\n\n    for name, scorer in SCORERS.items():\n        if name in MULTILABEL_ONLY_SCORERS:\n            target = y_ml_test\n        else:\n            target = y_test\n        try:\n            weighted = scorer(estimator[name], X_test, target,\n                              sample_weight=sample_weight)\n            ignored = scorer(estimator[name], X_test[10:], target[10:])\n            unweighted = scorer(estimator[name], X_test, target)\n            assert_not_equal(weighted, unweighted,\n                             msg=\"scorer {0} behaves identically when \"\n                             \"called with sample weights: {1} vs \"\n                             \"{2}\".format(name, weighted, unweighted))\n            assert_almost_equal(weighted, ignored,\n                                err_msg=\"scorer {0} behaves differently when \"\n                                \"ignoring samples and setting sample_weight to\"\n                                \" 0: {1} vs {2}\".format(name, weighted,\n                                                        ignored))\n\n        except TypeError as e:\n            assert_true(\"sample_weight\" in str(e),\n                        \"scorer {0} raises unhelpful exception when called \"\n                        \"with sample weights: {1}\".format(name, str(e)))\n\n\n@ignore_warnings  # UndefinedMetricWarning for P / R scores\ndef check_scorer_memmap(scorer_name):\n    scorer, estimator = SCORERS[scorer_name], ESTIMATORS[scorer_name]\n    if scorer_name in MULTILABEL_ONLY_SCORERS:\n        score = scorer(estimator, X_mm, y_ml_mm)\n    else:\n        score = scorer(estimator, X_mm, y_mm)\n    assert isinstance(score, numbers.Number), scorer_name\n\n\ndef test_scorer_memmap_input():\n    # Non-regression test for #6147: some score functions would\n    # return singleton memmap when computed on memmap data instead of scalar\n    # float values.\n    for name in SCORERS.keys():\n        yield check_scorer_memmap, name\n\n\ndef test_deprecated_names():\n    X, y = make_blobs(random_state=0, centers=2)\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n    clf = LogisticRegression(random_state=0)\n    clf.fit(X_train, y_train)\n\n    for name in ('mean_absolute_error', 'mean_squared_error',\n                 'median_absolute_error', 'log_loss'):\n        warning_msg = \"Scoring method %s was renamed to\" % name\n        for scorer in (get_scorer(name), SCORERS[name]):\n            assert_warns_message(DeprecationWarning,\n                                 warning_msg,\n                                 scorer, clf, X, y)\n\n        assert_warns_message(DeprecationWarning,\n                             warning_msg,\n                             cross_val_score, clf, X, y, scoring=name)\n\n\ndef test_scoring_is_not_metric():\n    assert_raises_regexp(ValueError, 'make_scorer', check_scoring,\n                         LogisticRegression(), f1_score)\n    assert_raises_regexp(ValueError, 'make_scorer', check_scoring,\n                         LogisticRegression(), roc_auc_score)\n    assert_raises_regexp(ValueError, 'make_scorer', check_scoring,\n                         Ridge(), r2_score)\n    assert_raises_regexp(ValueError, 'make_scorer', check_scoring,\n                         KMeans(), adjusted_rand_score)\n", "#!/usr/bin/env python\n#\n# Copyright 2013 Quantopian, Inc.\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#     http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nimport matplotlib.pyplot as plt\n\nfrom zipline.algorithm import TradingAlgorithm\nfrom zipline.utils.factory import load_from_yahoo\n\n# Import exponential moving average from talib wrapper\nfrom zipline.transforms.ta import EMA\n\nfrom datetime import datetime\nimport pytz\n\n\nclass DualEMATaLib(TradingAlgorithm):\n    \"\"\"Dual Moving Average Crossover algorithm.\n\n    This algorithm buys apple once its short moving average crosses\n    its long moving average (indicating upwards momentum) and sells\n    its shares once the averages cross again (indicating downwards\n    momentum).\n\n    \"\"\"\n    def initialize(self, short_window=20, long_window=40):\n        # Add 2 mavg transforms, one with a long window, one\n        # with a short window.\n        self.short_ema_trans = EMA(timeperiod=short_window)\n        self.long_ema_trans = EMA(timeperiod=long_window)\n\n        # To keep track of whether we invested in the stock or not\n        self.invested = False\n\n    def handle_data(self, data):\n        self.short_ema = self.short_ema_trans.handle_data(data)\n        self.long_ema = self.long_ema_trans.handle_data(data)\n        if self.short_ema is None or self.long_ema is None:\n            return\n\n        self.buy = False\n        self.sell = False\n\n        if (self.short_ema > self.long_ema).all() and not self.invested:\n            self.order('AAPL', 100)\n            self.invested = True\n            self.buy = True\n        elif (self.short_ema < self.long_ema).all() and self.invested:\n            self.order('AAPL', -100)\n            self.invested = False\n            self.sell = True\n\n        self.record(AAPL=data['AAPL'].price,\n                    short_ema=self.short_ema['AAPL'],\n                    long_ema=self.long_ema['AAPL'],\n                    buy=self.buy,\n                    sell=self.sell)\n\nif __name__ == '__main__':\n    start = datetime(1990, 1, 1, 0, 0, 0, 0, pytz.utc)\n    end = datetime(1991, 1, 1, 0, 0, 0, 0, pytz.utc)\n    data = load_from_yahoo(stocks=['AAPL'], indexes={}, start=start,\n                           end=end)\n\n    dma = DualEMATaLib()\n    results = dma.run(data).dropna()\n\n    fig = plt.figure()\n    ax1 = fig.add_subplot(211, ylabel='portfolio value')\n    results.portfolio_value.plot(ax=ax1)\n\n    ax2 = fig.add_subplot(212)\n    results[['AAPL', 'short_ema', 'long_ema']].plot(ax=ax2)\n\n    ax2.plot(results.ix[results.buy].index, results.short_ema[results.buy],\n             '^', markersize=10, color='m')\n    ax2.plot(results.ix[results.sell].index, results.short_ema[results.sell],\n             'v', markersize=10, color='k')\n    plt.legend(loc=0)\n    plt.gcf().set_size_inches(18, 8)\n", "\"\"\"\n=======================================\nReceiver Operating Characteristic (ROC)\n=======================================\n\nExample of Receiver Operating Characteristic (ROC) metric to evaluate\nclassifier output quality.\n\nROC curves typically feature true positive rate on the Y axis, and false\npositive rate on the X axis. This means that the top left corner of the plot is\nthe \"ideal\" point - a false positive rate of zero, and a true positive rate of\none. This is not very realistic, but it does mean that a larger area under the\ncurve (AUC) is usually better.\n\nThe \"steepness\" of ROC curves is also important, since it is ideal to maximize\nthe true positive rate while minimizing the false positive rate.\n\nROC curves are typically used in binary classification to study the output of\na classifier. In order to extend ROC curve and ROC area to multi-class\nor multi-label classification, it is necessary to binarize the output. One ROC\ncurve can be drawn per label, but one can also draw a ROC curve by considering\neach element of the label indicator matrix as a binary prediction\n(micro-averaging).\n\n.. note::\n\n    See also :func:`sklearn.metrics.roc_auc_score`,\n             :ref:`example_model_selection_plot_roc_crossval.py`.\n\n\"\"\"\nprint(__doc__)\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import svm, datasets\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.cross_validation import train_test_split\nfrom sklearn.preprocessing import label_binarize\nfrom sklearn.multiclass import OneVsRestClassifier\n\n# Import some data to play with\niris = datasets.load_iris()\nX = iris.data\ny = iris.target\n\n# Binarize the output\ny = label_binarize(y, classes=[0, 1, 2])\nn_classes = y.shape[1]\n\n# Add noisy features to make the problem harder\nrandom_state = np.random.RandomState(0)\nn_samples, n_features = X.shape\nX = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n\n# shuffle and split training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n                                                    random_state=0)\n\n# Learn to predict each class against the other\nclassifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n                                 random_state=random_state))\ny_score = classifier.fit(X_train, y_train).decision_function(X_test)\n\n# Compute ROC curve and ROC area for each class\nfpr = dict()\ntpr = dict()\nroc_auc = dict()\nfor i in range(n_classes):\n    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n    roc_auc[i] = auc(fpr[i], tpr[i])\n\n# Compute micro-average ROC curve and ROC area\nfpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\nroc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr[2], tpr[2], label='ROC curve (area = %0.2f)' % roc_auc[2])\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc=\"lower right\")\nplt.show()\n\n# Plot ROC curve\nplt.figure()\nplt.plot(fpr[\"micro\"], tpr[\"micro\"],\n         label='micro-average ROC curve (area = {0:0.2f})'\n               ''.format(roc_auc[\"micro\"]))\nfor i in range(n_classes):\n    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})'\n                                   ''.format(i, roc_auc[i]))\n\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Some extension of Receiver operating characteristic to multi-class')\nplt.legend(loc=\"lower right\")\nplt.show()\n", "\n\nimport requests\nimport json\nimport numpy as np\nimport pandas as pd\nimport CoHouseToken\nfrom difflib import SequenceMatcher\n\n\n\n# In[3]:\n\n\ndef exactMatch(line1, line2):\n    line1=line1.upper().rstrip()    \n    line2=line2.upper().rstrip()\n    #print(\"|\"+line1+\"|\"+line2+\"|\",line1==line2)\n    return line1==line2\n\n\n\n\ndef aStopWord(word):\n    return word.upper().replace(\"COMPANY\",\"CO\").replace(\"LIMITED\",\"LTD\").replace(\"&\",\"AND\").rstrip() \n\n\n\n\n\ndef spaces(word):\n    w = word.upper().replace(\"/\",\" \")\n    w = w.replace(\".\",\" \").replace(\",\",\" \").replace(\"-\",\" \").rstrip() \n    return w\n\n\n\n\n\ndef removeAStopWord(word):\n    w = word.upper().replace(\"LTD\",\" \").replace(\"CO\",\" \").replace(\"AND\",\" \").replace(\"(\",\" \").replace(\"/\",\" \")\n    w = w.replace(\")\",\" \").replace(\".\",\" \").replace(\",\",\" \").replace(\"-\",\" \").rstrip() \n    return w\n\n\n\n\n\ndef removeABlank(word):\n    w = word.replace(\" \",\"\")\n    return w\n\n\n\n\n\ndef removeABracket (line):\n    flag = False\n    word=\"\"\n    for a in line:\n        if a==\"(\":\n            flag = True\n            a=\"\"\n        if a==\")\":\n            a=\"\"\n            flag = False\n        if flag:\n            a=\"\"\n        word+=a\n    return word\n    \n\n\n\n\n\ndef stopWord(line1, line2):\n    line1=aStopWord(line1)  \n    line2=aStopWord(line2)\n    #print(\"|\"+line1+\"|\"+line2+\"|\",line1==line2)\n    return line1==line2\n\n\n\n\n\ndef removeStopWord(line1, line2):\n    line1=spaces(line1)  \n    line2=spaces(line2)\n    line1=aStopWord(line1)  \n    line2=aStopWord(line2)\n    line1=removeAStopWord(line1)  \n    line2=removeAStopWord(line2)\n    #print(\"|\"+line1+\"|\"+line2+\"|\",line1==line2)\n    return line1==line2\n\n\n\n\n\ndef removeBlanks(line1, line2):\n    line1=spaces(line1)  \n    line2=spaces(line2)\n    line1=aStopWord(line1)  \n    line2=aStopWord(line2)\n    line1=removeAStopWord(line1)  \n    line2=removeAStopWord(line2)\n    line1=removeABlank(line1)  \n    line2=removeABlank(line2)\n    return line1==line2\n\n\n\n\n\ndef removeBrackets(line1, line2):\n    line1=removeABracket(line1)  \n    line2=removeABracket(line2)\n    line1=spaces(line1)  \n    line2=spaces(line2)\n    line1=aStopWord(line1)  \n    line2=aStopWord(line2)\n    line1=removeAStopWord(line1)  \n    line2=removeAStopWord(line2)\n    line1=removeABlank(line1)  \n    line2=removeABlank(line2)\n   #print(\"|\"+line1+\"|\"+line2+\"|\",line1==line2)\n    \n    return line1==line2\n\n\n\n\n\ndef strip(line1, line2):\n    line1=removeABracket(line1)  \n    line2=removeABracket(line2)\n    line1=spaces(line1)  \n    line2=spaces(line2)\n    line1=aStopWord(line1)  \n    line2=aStopWord(line2)\n    line1=removeAStopWord(line1)  \n    line2=removeAStopWord(line2)\n    line1=removeABlank(line1)  \n    line2=removeABlank(line2)\n    \n    return line1,line2\n\n\n\n\n\ndef match(company,results):\n    for i in results['items']:\n        line = i['title']\n        number = i['company_number']\n        if(exactMatch(company,line)):\n            return True,line,number\n            \n    for i in results['items']:\n        line = i['title']\n        number = i['company_number']\n        if(stopWord(company,line)):\n            return True,line,number\n            \n    for i in results['items']:\n        line = i['title']\n        number = i['company_number']\n        if(removeStopWord(company,line)):\n            return True,line,number\n            \n    for i in results['items']:\n        line = i['title']\n        number = i['company_number']\n        if(removeBlanks(company,line)):\n            return True,line,number\n            \n    for i in results['items']:\n        line = i['title']\n        number = i['company_number']\n        if(removeBrackets(company,line)):\n            return True,line,number\n        \n        #old_match(company,results)\n    return False,\"\",\"\"\n\n\n\n\ndef main(args):\n    print(args[0])\n    search_url =\"https://api.companieshouse.gov.uk/search/companies?q=\"\n    token = CoHouseToken.getToken()\n    pw = ''\n    base_url = 'https://api.companieshouse.gov.uk'\n    file = args[1]\n    print(file)\n    df = pd.read_csv(file,names=['Organisation'])\n    companies = df.Organisation\n    count=0\n    found = open(\"found2.csv\",'w')\n    missing = open(\"missing2.csv\",'w')\n\n    for c in companies:\n        c =c.upper().replace(\"&\",\"AND\")\n        c = c.split(\" T/A \")[0]\n        c = c.split(\"WAS \")[0]\n        c= spaces(c)\n        url=search_url+c\n        results = json.loads(requests.get(url, auth=(token,pw)).text)\n        for i , key  in enumerate(results['items']):\n            a,b = strip(c, key['title'])\n            r = SequenceMatcher(None, a, b).ratio()\n            print(\"%s \\t %s\\t %.2f \\t %s \\t %s\"%(i,c,r,key['company_number'],key['title']))\n        \n        v = input('type number or return to reject: ')\n        if v ==\"\":\n            print(\"reject\")\n            missing.write(\"%s\\n\"%(c))\n        else:\n            key = results['items'][int(v)]\n            print(\"%s \\t %s\\t %.2f \\t %s \\t %s\"%(v,c,r,key['company_number'],key['title']))\n            print(\"*************************\")\n            found.write(\"%s,%s,%s,\\n\"%(c,key['title'],key['company_number']))\n        \n            \n    print()\n    #print(count/len(companies))\n\n\n\n\n    return 0\n\nif __name__ == '__main__':\n    import sys\n    sys.exit(main(sys.argv))\n\n\n\n\n\n", "'''\nThis is a dummy file for me to get started making an Ising model. I'll get this 2-D Ising running, then generalize.\n'''\n\nimport argparse\nfrom itertools import izip\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\ndef run_ising(N, d, K, J,h, n_steps, plot = False):\n    '''\n\n    :param N:\n    :param d:\n    :param K:\n    :param J:\n    :param h:\n    :param n_steps:\n    :param plot:\n    :return:\n    '''\n\n    if plot:\n        try:\n            assert d <= 2\n        except AssertionError:\n            raise AssertionError(\"Can only plot in one or two dimensions.\")\n\n    #TODO wrap these better\n    assert N >0 and N < 1000\n    assert d > 0\n    assert n_steps > 0\n\n    np.random.seed(0)\n\n    size = tuple(N for i in xrange(d))\n    lattice = np.ones(size)\n    #make a random initial state\n    lattice-= np.random.randint(0,2, size =size)*2\n\n    # do different initialization\n    E_0 = energy(lattice, potential, K, h)\n    if plot:\n        plt.ion()\n    for step in xrange(n_steps):\n        if step%1000 == 0:\n            print step\n        site = tuple(np.random.randint(0, N, size=d))\n        # consider flipping this site\n        lattice[site] *= -1\n        E_f = energy(lattice, potential, K, h)\n\n        # if E_F < E_0, keep\n        # if E_F > E_0, keep randomly given change of energies\n        if E_f >= E_0:\n            keep = np.random.uniform() < np.exp(K / J * (E_0 - E_f))\n        else:\n            keep = True\n\n        if keep:\n            E_0 = E_f\n        else:\n            lattice[site] *= -1\n\n        # fig = plt.figure()\n        if plot and step % 100 == 0:\n            if d == 1:\n                plt.imshow(lattice.reshape((1, -1)),interpolation='none')\n            else:\n                plt.imshow(lattice, interpolation='none')\n            plt.title(correlation(lattice, N/2))\n            plt.pause(0.01)\n            plt.clf()\n\n    return np.array([correlation(lattice, r) for r in xrange(1, N/2+1)])\n\ndef get_NN(site, N, d, r= 1):\n    '''\n    The NN of the site. Will only return those UP in index (east, south, and down) to avoid double counting.\n    Accounts for PBC\n    :param site:\n        (d,) array of coordinates in the lattice\n    :param N:\n        Size of one side of the lattice\n    :param d:\n        dimension of the lattice\n    :return:\n        dxd numpy array where each row corresponds to the nearest neighbors.\n    '''\n    mult_sites = np.r_[ [site for i in xrange(d)]]\n    adjustment = np.eye(d)*r\n    return ((mult_sites+adjustment)%N).astype(int)\n\n\ndef potential(s1, s2, K, h):\n    '''\n    Basic Ising potential\n    :param s1:\n        First spin (-1 or 1)\n    :param s2:\n        Second spin\n    :param K:\n        Coupling constant\n    :return:\n        Energy of this particular bond\n    '''\n    return -1*K*s1*s2 - h/2*(s1+s2)#should this be abstracted to call the NN function?\n\ndef energy(lattice, potential, K, h = 0):\n    '''\n    Calculate the energy of a lattice\n    :param lattice:\n        Lattice to calculate the energy on\n    :param potential:\n        Function defining the potential of a given site.\n    :return:\n        Energy of the lattice\n    '''\n    N = lattice.shape[0]\n    d = len(lattice.shape)\n\n    dim_slices = np.meshgrid(*(xrange(N) for i in xrange(d)), indexing = 'ij')\n    all_sites = izip(*[slice.flatten() for slice in dim_slices])\n\n    E = 0\n    for site in all_sites:\n        nn = get_NN(site, N, d)\n        for neighbor in nn:\n            E+=potential(lattice[site], lattice[tuple(neighbor)],K = K, h = h)\n\n    return E\n\ndef magnetization(lattice):\n    return lattice.mean()\n\ndef correlation(lattice, r):\n    '''\n    The average spin correlation at distance r.\n    :param lattice:\n        The lattice to calculate the statistic on.\n    :param r:\n        Distance to measure correlation\n    :return:\n    '''\n    N = lattice.shape[0]\n    d = len(lattice.shape)\n\n    dim_slices = np.meshgrid(*(xrange(N) for i in xrange(d)), indexing='ij')\n    all_sites = izip(*[slice.flatten() for slice in dim_slices])\n\n    xi = 0\n    for site in all_sites:\n        nn = get_NN(site, N, d, r)\n        for neighbor in nn:\n            xi += lattice[site]*lattice[tuple(neighbor)]\n\n    return xi/((N**d)*d)\n\nif __name__  == '__main__':\n    parser = argparse.ArgumentParser(description='Simulate an ising model')\n    parser.add_argument('N', type = int, help = 'Length of one side of the cube.')\n    parser.add_argument('d', type = int, help = 'Number of dimensions of the cube.')\n    #parser.add_argument('K', type = float, help ='Bond coupling strength.')\n\n    parser.add_argument('J', type = float, default = 1.0, nargs = '?',\\\n                        help = 'Energy of bond strength. Optional, default is 1.')\n    parser.add_argument('h', type = float, default=0.0, nargs = '?',\\\n                        help = 'Magnetic field strength. Optional, default is 0.')\n    parser.add_argument('n_steps', type = int, default = 1000, nargs = '?',\\\n                        help = 'Number of steps to simulate. Default is 1e5')\n    parser.add_argument('--plot', action = 'store_true',\\\n                        help = 'Whether or not to plot results. Only allowed with d = 1 or 2.')\n\n    args = parser.parse_args()\n    spins = []\n    Ks = [ 0.5,0.6,0.65, 0.7,0.8, 0.9]\n    for K in Ks:\n        print K\n        spins.append(run_ising(K = K, **vars(args)))\n\n    for K, spin in izip(Ks, spins):\n        plt.plot(spin, label = K )\n    plt.legend(loc = 'best')\n    plt.ylim([-0.1, 1.1])\n    plt.show()"], "license": ["bsd-3-clause", "bsd-3-clause", "mit", "bsd-3-clause", "mit", "apache-2.0", "bsd-3-clause", "gpl-3.0", "mit"]}